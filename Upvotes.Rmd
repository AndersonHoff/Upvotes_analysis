---
title: "UpVotes Challenge: Analysis and Prediction" 
author: "Author: Anderson Hoff"
date: "Last update: `r format(Sys.time(), '%d %B, %Y')`" 
output:
  html_document:
    toc: FALSE
    toc_float:
        collapsed: true
        smooth_scroll: true
    toc_depth: 3
    fig_caption: yes
    number_sections: False
fontsize: 14pt
---

<!-- Compile from command-line
Rscript -e "rmarkdown::render('Upvotes.Rmd', c('html_document'), clean=FALSE)"
-->

<!-- To comment a line Ctrl+Shift+C -->

#  {.tabset .tabset-fade .tabset-pills}

## Overview
<br>
The main objective of this project is to learn and practice some technical duties about data analysis and graphic generation. Also, I tested different predictive models, focused on the behavior and differences between them. Last, but not least, that is an excellent oportunity to practice my English skills.  

The challenge of this problem is related to identify the best question authors on an online question and answer platform. This identification will bring more insight into increasing the user engagement. Given the tag of the question, number of views received, number of answers, username and reputation of the question author, the problem requires you to predict the upvote count that the question will receive.
This test is provided by [Analytics Vidhya](https://datahack.analyticsvidhya.com/contest/enigma-codefest-machine-learning-1/).  

## Required packages

```{r library, eval=TRUE, echo=TRUE, message=FALSE, warning=FALSE}
if(!require(dplyr)) {istall.packages("dplyr")} else {library(dplyr)}
if(!require(ggplot2)) {install.packages("ggplot2")} else {library(ggplot2)}
if(!require(magrittr)) {install.packages("magrittr")} else {library(magrittr)} # for pipe
if(!require(caTools)) {install.packages("caTools")} else {library(caTools)} # for data partition
if(!require(ModelMetrics)) {install.packages("ModelMetrics")} else {library(ModelMetrics)} # for rmse
if(!require(corrplot)) {install.packages("corrplot")} else {library(corrplot)} # correlation matrix
if(!require(knitr)) {install.packages("knitr")} else {library(knitr)} # for floating tables 
```

## Data analysis

### Load data

The data used in this analysis is composed by a training set and a test set. In this part I will be dealing with the training dataset. This is how it looks like.

```{r LoadData, eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
train_data = read.csv('train_data.csv')

train_data <- train_data %>%
  select(Upvotes, everything()) 

kable(train_data[1:10,], align="cr")

```

| Variable  | Definition |
|:---------:|:----------:|
Upvotes | Number of upvotes for the question (TARGET) 
ID | Question ID
Tag | Anonymised tags representing question category
Reputation | Reputation score of author
Answer | Number of times question has been answered
Username | Anonymised user id of question author
Views | Number of times question has been viewed

As can be seen, the target is to predict the number of positive votes a question receive, based on the features described above.  
The table below show the type of each column of the data. Apart from "TAG", all other columns are numeric.
```{r, eval=TRUE, echo=FALSE}
glimpse(train_data)

summary(train_data)

```
It is important to identify missing values (NA's) on the tables, from both numeric ans categorical data. The result obtained below tell us that there are not empty cells in the numeric columns.

```{r, eval=TRUE, echo=TRUE}

sum(is.na(train_data))

levels(train_data$Tag)
```

Also, there is not a blank categorical cell in the TAG column, since the line above contain only letters.  
These results means the dataset is usable and we can start try to extract relevant information from it.

### Graphs of data {.tabset .tabset-fade .tabset-pills}

In order to observe how the data is spread in each column, some graphs  and tables were created. The ID column contain a different number to identify each question, and this nuber is never repeated. By this way, we will not use this column in the analysis.  

#### Tag 
```{r}
table(train_data$Tag)
```
<br>
The table above show us the question category is spread in different letters, and the graph below indicates it is reasobly distributed between them.  

```{r}
ggplot(train_data, aes(x=Tag)) +
  geom_bar(aes(fill=Tag)) + 
  ggtitle("TAG frequency")+
  coord_flip()+
  theme_bw()+
  ylab("Frequency")+
  xlab("TAG")
```

#### Reputation
```{r}
summary(train_data$Reputation)
reputation_groups <- cut(train_data$Reputation, breaks = 10, labels = FALSE)
table(reputation_groups)
```
<br>
From the table above, we observe that almost all of Reputation data is in the first column. This means most of the Reputation is low, and in this case, a graphic will not add any knowledge.  

#### Answers

```{r, eval=TRUE}
summary(train_data$Answers)

ggplot(train_data, aes(x=Answers)) +
  geom_bar(aes(fill=Answers)) + 
  ggtitle("Answers frequency")+
  coord_flip()+
  theme_bw()+
  ylab("Frequency")+
  xlab("Answers")
```

#### Usernames

```{r, eval=TRUE}
summary(train_data$Username)
Usernames <- cut(train_data$Username, breaks = 10, labels = FALSE)
table(Usernames)

ggplot(train_data, aes(x=Usernames)) +
  geom_bar(aes(fill=Usernames)) + 
  ggtitle("Usernames frequency")+
  coord_flip()+
  ylab("Number of frequency")+
  xlab("Usernames")


summary(train_data$Views)
Views <- cut(train_data$Views, breaks = 10, labels = FALSE)
table(Views)
```

```{r, echo=FALSE}
#hist(Views)
#train_data$Views <- log10(train_data$Views)
#hist(logViews)
```

#### Upvotes

```{r, eval=TRUE}
summary(train_data$Upvotes)
Upvotes <- cut(train_data$Upvotes, breaks = 10, labels = FALSE)
table(Upvotes)

numeric.var <- sapply(train_data, is.numeric)
corr.matrix <- cor(train_data[,numeric.var])
corrplot(corr.matrix, main="\n\nCorrelation Plot for Numerical Variables", 
         method="circle")
```

In statistics, the correlation coefficient *cc* measures the strength and direction of a linear relationship between two variables on a scatterplot. The value of *cc* is always between +1 and –1. To interpret its value, see which of the following values your correlation *cc* is closest to: 

* -1 : indicates a strong negative correlation (if one variable increases, the other decreases).  
* 0 : there is no association between the two variables.  
* +1 : indicates a stron positive correlation: (both variables vary in the same way).  
<br>
From the results, we observe there is no correlation between Upvotes (the target) and ID or Username. Since there is one ID for each question, this result is reasonable. The same occurs for Username.  
Due to these results, we skip these two columns for the training process.

```{r}
train_data <- train_data %>%
  select( -Username)
```

## Predictive Models {.tabset .tabset-fade .tabset-pills}

We start here the data forecast for this problem, Only to emphasize, the evaluation metric for this competition is RMSE (root mean squared error).  
The RMSE is a standard way to measure the error of a model in predicting quantitative data. Formally it is defined as 
$$RMSE = \sqrt{\sum(ŷ_i - y_i)/n}$$
The RMSE can be tought as a distance between the vector of predicted values and the vector of observed values.

### Linear Regression Model  

```{r, eval=TRUE}

set.seed(seed = 2019)
split = sample.split(train_data, SplitRatio = 0.7)#SplitRatio indicates the size of the training set
train_set = subset(train_data, split == TRUE)
test_set = subset(train_data, split == FALSE)

lmmodel <- lm(Upvotes ~ +Tag +Reputation +Answers +Views, 
              data = train_set, singular.ok = TRUE)
anova(lmmodel)
summary(lmmodel)

plot(lmmodel, which=1, caption = list("Residuals vs Fitted"))
```

This plot shows if residuals have non-linear patterns. There could be a non-linear relationship between predictor variables and an outcome variable and the pattern could show up in this plot if the model doesn’t capture the non-linear relationship. 

```{r, eval=TRUE}
plot(lmmodel, which=2, caption = list("", "Normal Q-Q"))
```

This plot shows if residuals are normally distributed. Do residuals follow a straight line well or do they deviate severely? It’s good if residuals are lined well on the straight dashed line.

```{r}
plot(lmmodel, which=3, caption = list("", "", "Scale-Location"))

```

It’s also called Spread-Location plot. This plot shows if residuals are spread equally along the ranges of predictors. This is how you can check the assumption of equal variance (homoscedasticity). It’s good if you see a horizontal line with equally (randomly) spread points.

```{r}
plot(lmmodel, which=5, caption = list("", "", "", "", "Residuals vs Leverage"))
```

This plot helps us to find influential cases (i.e., subjects) if any. Not all outliers are influential in linear regression analysis (whatever outliers mean). Even though data have extreme values, they might not be influential to determine a regression line. That means, the results wouldn’t be much different if we either include or exclude them from analysis. They follow the trend in the majority of cases and they don’t really matter; they are not influential. On the other hand, some cases could be very influential even if they look to be within a reasonable range of the values. They could be extreme cases against a regression line and can alter the results if we exclude them from analysis. Another way to put it is that they don’t get along with the trend in the majority of the cases.

Source of graphic explanation: [University of Virginia](https://data.library.virginia.edu/diagnostic-plots/)

```{r, eval=TRUE}
predict_lm <- predict(lmmodel, newdata =  test_set, 
                                        type = "response",
                                        interval = "confidence",
                                        family = poisson(link = ))

predict <- as.data.frame(predict_lm)

test_set$predict <- predict$fit

ggplot()+
  geom_point(data=test_set, aes(x=ID, y=Upvotes), fill="red") +
  geom_point(data=test_set, aes(x=ID, y=predict), fill="blue", colour="darkblue")

rmse_lm <- as.integer(rmse(test_set$Upvotes, test_set$predict))
```

<!-- The RMSE for the testing sample is `r rmse_lm`. -->

<br>
To generate the results for the Testing sample, just run the code below, which generates a .csv file with the respective results. 

```{r, eval=FALSE}
test_data = read.csv('test_data.csv')
test_data$predict <- predict.lm(lmmodel, newdata = test_data, 
                                type = "response",
                                interval = "confidence",
                                family = poisson())

test_data$predict <- as.integer(test_data$predict)

write.table(cbind(test_data$ID,test_data$predict),
            file="Upvotes_LM.csv", 
            sep = ",", quote = FALSE, col.names = c('ID','Upvotes'), 
            row.names=F)
```

### Non-Linear Regresion Model  

```{r, eval=FALSE}
set.seed(seed = 2020)
split = sample.split(train_data, SplitRatio = 0.7)
train_set = subset(train_data, split == TRUE)
test_set = subset(train_data, split == FALSE)

glmmodel <- glm(Upvotes ~ ., 
                train_set, family = quasi(link = "identity"))
#anova(glmmodel)
summary(glmmodel)
#plot(glmmodel)

test_set$predict <- predict.glm(glmmodel, newdata =  test_set,
                                type = "response",
                                family = poisson())

nlm_rmse <- rmse(test_set$Upvotes, test_set$predict)
#3624  3108
```

<!-- The RMSE for the testing sample is ` nlm_rmse`. -->

### Neural net prediction  

```{r, eval=FALSE}
library(neuralnet)
train_net <- train_data %>%
  select(-Tag, - Upvotes)

Upvotes <- select(train_data, 1)

norm.fun = function(x){ 
  (x - min(x))/(max(x) - min(x)) 
}

data.norm = apply(train_net, 2, norm.fun)

data <- as.data.frame(data.norm)

train_net <- cbind(Upvotes, data)

set.seed(seed = 2019)
split = sample.split(train_net, SplitRatio = 0.1)#SplitRatio indicates the size of the training set
train_set = subset(train_net, split == TRUE)
test_set = subset(train_net, split == FALSE)


nnmodel <- neuralnet(train_net$Upvotes ~ +Reputation +Answers +Username +Views, 
                     data = train_net,
                     linear.output = FALSE,
                     hidden = 2,
                     threshold=0.01,
                     lifesign = "minimum",
                     rep = 3)
#print(nnmodel)
#plot(nnmodel)
```

### XGBoost analysis  

```{r, eval=TRUE, warning=FALSE, message=FALSE}

if(!require (xgboost)) {install.packages("xgboost")} else {library(xgboost)}
if(!require (Matrix)) {install.packages("Matrix")} else {library(Matrix)}
if(!require (Ckmeans.1d.dp)) {install.packages("Ckmeans.1d.dp")} else {library(Ckmeans.1d.dp)}

number <- 2020
set.seed(seed = number)
split = sample.split(train_data, SplitRatio = 0.7)
train_set = subset(train_data, split == TRUE)
test_set = subset(train_data, split == FALSE)
```

```{r, eval=TRUE, warning=FALSE, message=FALSE}
traindumb <- sparse.model.matrix(Upvotes ~. -1 , data = train_set)

train_label <- train_set[,"Upvotes"]

mtrain_set <- xgb.DMatrix(data = as.matrix(traindumb), label = train_label)
#print(mtrain_set, verbose = TRUE)

testdumb <- sparse.model.matrix(Upvotes ~. -1, data = test_set)

test_label <- test_set[,"Upvotes"]

mtest_set <- xgb.DMatrix(data = as.matrix(testdumb), label = test_label)

xgb_param <- list("booster" = "gblinear", 
                  "lambda L2" = 1,
                  "objective" = "reg:logistic", 
                  "eval_metric" = "rmsle")

watchlist <- list(train = mtrain_set, test = mtest_set)
```

```{r, eval=FALSE, echo=FALSE, warning=FALSE, message=FALSE}
xgbmodel <- xgb.train(parameters = xgb_param, 
                      data = mtrain_set, 
                      max.depth = 10,
                      watchlist = watchlist,
                      nrounds = 40,
                      eta = 0.1)
```

```{r, eval=FALSE, warning=FALSE, message=FALSE}
eval <- data.frame(xgbmodel$evaluation_log)
plot(eval$iter, eval$test_rmse, col = 'blue')

xgbimpor<- xgb.importance(model = xgbmodel)
xgb.ggplot.importance(xgbimpor)

pred <- predict(xgbmodel, newdata = mtest_set)

result <- as.data.frame(cbind(test_set$Upvotes, pred))

xgb_rmse <- as.integer(rmse(test_set$Upvotes, pred))

ggplot(result,aes(result$pred, result$V1)) + geom_point(color = "darkred", alpha = 0.5) + 
  geom_smooth(method=lm)+ ggtitle('Linear Regression ') + ggtitle("Extreme Gradient Boosting: Prediction vs Test Data") +
  xlab("Predecited Upvotes") + ylab("Observed Upvotes") + 
  theme(plot.title = element_text(color="darkgreen",size=16,hjust = 0.5),
        axis.text.y = element_text(size=12), axis.text.x = element_text(size=12,hjust=.5),
       axis.title.x = element_text(size=14), axis.title.y = element_text(size=14))

rm(split, test_label,test_set, train_label, train_set, testdumb, traindumb,
   watchlist,xgbmodel, xgb_param, result, eval, mtest_set, mtrain_set)
```

<!-- For the XGBoost analysis, the RMSE for the testing sample is ` xgb_rmse`. -->

### Keras analysis  


## Summary Results

